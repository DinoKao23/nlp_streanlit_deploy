{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data crawling\n",
    "\n",
    "We first crawl movie reviews of Verified Audience on Rotten Tomatoes. These reviews provide star ratings which allow for easy and automatic labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_source(html_source, n=10):\n",
    "    \"\"\"\n",
    "    This function creates a web driver to access a movie review page on rottentomatoes\n",
    "    and performs n clicks on the load more button to load more reviews beyond the display limit.\n",
    "    html_source: str, the url of the movie review page\n",
    "    n: int, the number of times to click the load more button\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the web driver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(html_source)\n",
    "    driver.implicitly_wait(50)\n",
    "\n",
    "    try:\n",
    "        # Click the load button\n",
    "        clickable = driver.find_element(By.CLASS_NAME, 'load-more-container')\n",
    "        \n",
    "        # Click it n times to load more content\n",
    "        for _ in range(n):\n",
    "            action_chains = ActionChains(driver)\n",
    "            action_chains.click(clickable).perform()\n",
    "            WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.CLASS_NAME, 'load-more-container')))\n",
    "            time\n",
    "            clickable = driver.find_element(By.CLASS_NAME, 'load-more-container')  # Update clickable element\n",
    "    except NoSuchElementException:\n",
    "        # If no more load-more button is found, stop clicking\n",
    "        pass\n",
    "    \n",
    "    driver.implicitly_wait(2)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(driver):\n",
    "    \"\"\"\n",
    "    This function collects the star ratings and comments from the movie review page given the web driver.\n",
    "    driver: the web driver to the movie review page\n",
    "    \"\"\"\n",
    "    # Find all comments\n",
    "    comment_elements = driver.find_elements(By.CSS_SELECTOR, 'p.audience-reviews__review.js-review-text[data-qa=\"review-text\"]')\n",
    "    comment_texts = [comment.text.strip() for comment in comment_elements]\n",
    "\n",
    "    # Find the star elements and extract the star ratings\n",
    "    html_content = driver.page_source\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    stars = soup.find_all(\"span\", class_=\"audience-reviews__score\")\n",
    "    # ratings = number of full stars + 0.5 * number of half stars\n",
    "    star_ratings = [len(star.find_all(\"span\", class_=\"star-display__filled\")) +\n",
    "                    0.5 * len(star.find_all(\"span\", class_=\"star-display__half\"))\n",
    "                    for star in stars]\n",
    "    \n",
    "    df = pd.DataFrame({\"star\": star_ratings, \"Verfied_Audience_Comment\":comment_texts})\n",
    "    df.reset_index(drop=True , inplace=True)\n",
    "    \n",
    "    driver.quit()\n",
    "    time.sleep(3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the movie urls stored in a csv file\n",
    "# can crawl more movies by adding more urls to the csv file\n",
    "movie_urls = pd.read_csv(\"Movie_List.csv\")\n",
    "movie_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect reviews and ratings for each movie in the list\n",
    "df_list = []\n",
    "for url in movie_urls['Title']:\n",
    "    # try:\n",
    "    driver = data_source(url)\n",
    "    df = collect_data(driver)\n",
    "    print(url, \"success\", f'{df.shape[0]} reviews collected')\n",
    "    df_list.append(df)\n",
    "    # except:\n",
    "    #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat(df_list, ignore_index=True)\n",
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the sentiment of the reviews\n",
    "# stars < 3: negative (-1)\n",
    "# 3 <= stars < 4: neutral (0)\n",
    "# stars >= 4: positive (1)\n",
    "def label_sentiment(df, column):\n",
    "    df['label'] = 0\n",
    "    df.loc[df[column] < 3, 'label'] = -1\n",
    "    df.loc[(3 <= df[column]) & (df['star']< 4), 'label'] = 0\n",
    "    df.loc[df[column] >= 4, 'label'] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the sentiment of the reviews and save the data\n",
    "concat_df = label_sentiment(concat_df, 'star')\n",
    "concat_df.to_csv(\"action_movie.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "We then clean the collected data. The cleaning process involves 4 steps:\n",
    "1. Remove special characters but keep basic punctuation.\n",
    "2. Remove non-english reviews\n",
    "3. Remove stop words.\n",
    "4. Handle missing data (if any) and remove duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from langdetect import detect, LangDetectException\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('action_movie_v2.csv')\n",
    "\n",
    "# function to remove special characters but keep basic punctuation\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# apply the cleaning function\n",
    "data['Verfied_Audience_Comment'] = data['Verfied_Audience_Comment'].apply(clean_text)\n",
    "\n",
    "# function to detect English language\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "# filter out non-English reviews\n",
    "data = data[data['Verfied_Audience_Comment'].apply(is_english)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>Verfied_Audience_Comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>movie carried two charismatic leads, idris elb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>action person you. pure adrenaline rush. openi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>wow, get movie theaters describing movie isnt ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cool action story, great summer blockbuster</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lots fun dialogand great action. ill gladly wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star                           Verfied_Audience_Comment  label\n",
       "0   3.5  movie carried two charismatic leads, idris elb...      0\n",
       "1   3.5  action person you. pure adrenaline rush. openi...      0\n",
       "2   0.5  wow, get movie theaters describing movie isnt ...     -1\n",
       "4   4.0        cool action story, great summer blockbuster      1\n",
       "5   4.0  lots fun dialogand great action. ill gladly wa...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to lowercase\n",
    "data['Verfied_Audience_Comment'] = data['Verfied_Audience_Comment'].str.lower()\n",
    "\n",
    "# Remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['Verfied_Audience_Comment'] = data['Verfied_Audience_Comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Check for any missing values and drop\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show cleaned data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7463, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a CSV file\n",
    "data.to_csv('cleaned_action_movie_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering with BERT\n",
    "\n",
    "After the data is cleaned, we proceed to vectorize the data to prepare it for training machine learning models. We will use BERT -- a modern embedding method that transforms each sequence of words to a dense, multi-dimensional vector. This vectorized data will then be used to train machine learning models for movie review sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linkd\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\linkd\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, BertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# set seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>Verfied_Audience_Comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>movie carried two charismatic leads, idris elb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>action person you. pure adrenaline rush. openi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>wow, get movie theaters describing movie isnt ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cool action story, great summer blockbuster</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lots fun dialogand great action. ill gladly wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star                           Verfied_Audience_Comment  label\n",
       "0   3.5  movie carried two charismatic leads, idris elb...      0\n",
       "1   3.5  action person you. pure adrenaline rush. openi...      0\n",
       "2   0.5  wow, get movie theaters describing movie isnt ...     -1\n",
       "3   4.0        cool action story, great summer blockbuster      1\n",
       "4   4.0  lots fun dialogand great action. ill gladly wa...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('cleaned_action_movie_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the DistilBERT model and tokenizer from the transformers library\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# for better performance with the cost of increased runtime, we can use the BERT model instead of the DistilBERT model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we tokenize each review into a sequence of word indices in a fixed vocabulary\n",
    "tokenized = df['Verfied_Audience_Comment'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 3185, 3344, 2048, 23916]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0][:5] # first 5 word indices of the first review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT model can vectorize multiple reviews at once (called batching) but all reviews must have the same length to pass through the model. Therefore, we pad all reviews to a fixed length with a dummy token (indexed 0 in the vocabulary). To do that, we first find the length of the longest review in the data, and at the same time filter out any review that is longer than what the model can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0 # the maximum sequence length of the reviews\n",
    "for i, review in enumerate(tokenized.values):\n",
    "    if len(review) > max_len:\n",
    "        max_len = len(review)\n",
    "\n",
    "# pad the sequences to the maximum length\n",
    "padded = np.array([review + [0]*(max_len-len(review)) for i, review in enumerate(tokenized.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7463, 401)\n"
     ]
    }
   ],
   "source": [
    "print (padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum length of reviews is 401."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding: [101, 3185, 3344, 2048, 23916, 5260, 1010, 8909, 6935, 3449, 3676, 2092, 1012, 102]\n",
      "After padding: [  101  3185  3344  2048 23916  5260  1010  8909  6935  3449  3676  2092\n",
      "  1012   102     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "# verify that padding works as expected\n",
    "print ('Before padding:', tokenized[0][:50])\n",
    "print ('After padding:', padded[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the padded tokens are dummy, we want the BERT model to ignore these tokens when embedding each review. We do this by masking out these tokens when passing the padded tokenized reviews through the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0) # 0 means ignore\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "input_ids = torch.tensor(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids: tensor([  101,  3185,  3344,  2048, 23916,  5260,  1010,  8909,  6935,  3449,\n",
      "         3676,  2092,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       dtype=torch.int32)\n",
      "Attention mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print ('Input ids:', input_ids[0][:50])\n",
    "print ('Attention mask:', attention_mask[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# pass the input ids and attention mask to the model to get the embedding for each review\n",
    "batch_size = 512\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(input_ids), batch_size)):\n",
    "        batch_input_ids = input_ids[i:i+batch_size]\n",
    "        batch_attention_mask = attention_mask[i:i+batch_size]\n",
    "        batch_last_hidden_states = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        embeddings.append(batch_last_hidden_states[0][:,0,:].numpy())\n",
    "embeddings = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7464, 768)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Now we have vectorized the reviews to numpy arrays, we can use standard machine learning algorithms in sklearn to classify each review to one of 3 sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7464, 7464)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the labels and remove the skipped reviews\n",
    "labels = df['label']\n",
    "len(labels), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the labels\n",
    "labels.value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the positive reviews dominate in this dataset, while the neutral reviews are the minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to training and testing\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5598, 768), (5598,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1866, 768), (1866,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8135048231511254\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.59      0.62       236\n",
      "     Neutral       0.36      0.18      0.24       211\n",
      "    Positive       0.87      0.95      0.90      1419\n",
      "\n",
      "    accuracy                           0.81      1866\n",
      "   macro avg       0.62      0.57      0.59      1866\n",
      "weighted avg       0.78      0.81      0.79      1866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression classifier\n",
    "# Setting solver to 'lbfgs' as it can handle multinomial loss for multiclass problems\n",
    "# Increasing 'max_iter' might be necessary for convergence on some datasets\n",
    "lr_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=5000, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "lr_clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = lr_clf.predict(test_features)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "clf_report = classification_report(test_labels, test_predictions, target_names=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_analysis_model.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "import joblib\n",
    "joblib.dump(lr_clf, 'sentiment_analysis_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the performance of the model with a dummy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7604501607717041\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00       236\n",
      "     Neutral       0.00      0.00      0.00       211\n",
      "    Positive       0.76      1.00      0.86      1419\n",
      "\n",
      "    accuracy                           0.76      1866\n",
      "   macro avg       0.25      0.33      0.29      1866\n",
      "weighted avg       0.58      0.76      0.66      1866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tungnd/miniconda3/envs/bbo-llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tungnd/miniconda3/envs/bbo-llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tungnd/miniconda3/envs/bbo-llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "dummy_test_predictions = clf.predict(test_features)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(test_labels, dummy_test_predictions)\n",
    "dummy_clf_report = classification_report(test_labels, dummy_test_predictions, target_names=['Negative', 'Neutral', 'Positive'])\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(dummy_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs significantly better than the dummy model. However, it can also be seen that the model performs poorty w.r.t. negative and neutral reviews, which have less data points in the dataset compared to the positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbo-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
